{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_-IXcrzE8vT"
   },
   "source": [
    "# Week 4: Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03VWq_HvE8vU"
   },
   "source": [
    "## Preliminaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2509,
     "status": "ok",
     "timestamp": 1634371680454,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "q-nDt9YTFD8L",
    "outputId": "e7004718-39eb-4bb3-cbd8-59549843148a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download nltk resources\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRQXB_JOE8vb"
   },
   "source": [
    "## Overview \n",
    "In labs this week (and last), the focus is on the application of sentiment analysis. We have introduced the  **movie_review corpus** and started exploring various techniques that can be used to classify the sentiment of movie_reviews as either positive or negative. \n",
    "\n",
    "Last time, you developed your own **Word List** classifiers.  This time you will be developing a **Naïve Bayes** classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGUgXTG9E8vc"
   },
   "source": [
    "## Naïve Bayes classifiers\n",
    "\n",
    "We will introduce Naïve Bayes classifiers through a very simple example dataset involving documents that are either about the weather or football. The classifier will be trained to distinguish these two topics from one another.\n",
    "\n",
    "There are, therefore, two classes `weather` and `football`. The classifier's job is to determine whether a document that it is given is in the class `weather` or in the class `football`.\n",
    "\n",
    "We give the classifier examples of documents in the `weather` class, and examples of documents in the `football` class. For now, to keep things simple, our so-called documents will be very short phrases.\n",
    "\n",
    "Run the following cell to set up some training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1634371708294,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "KEEJmxRsE8vd"
   },
   "outputs": [],
   "source": [
    "# Some sentence data to get us started. It is deliberately VERY simple. \n",
    "\n",
    "weather_sents_train = [\n",
    "    \"today it is raining\",\n",
    "    \"looking cloudy today\",\n",
    "    \"it is nice weather\",\n",
    "]\n",
    "\n",
    "football_sents_train = [\n",
    "    \"city looking good\",\n",
    "    \"advantage united\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voSZw93KE8vi"
   },
   "source": [
    "### Assumptions\n",
    "One of the simplfying assumptions that is made with Naïve Bayes classification is that each document is taken to be a so-called **bag of words**. What this means is that the word order is ignored. For example, the document phrase \"city looking good\" will generate the same *bag* of words as \"good looking city\" and \"good city looking\"\n",
    "\n",
    "The second assumption that we are using a **multinomial** event where the number of times a words appears in a document is taken into account.  \n",
    "\n",
    "Given these assumptions, we will represent each training document as a pair consisting of a dictionary that maps each word that appears in the document to f (where f is the frequency of the word in the document), and a string denoting the class of the document. \n",
    "\n",
    "There are other event models (**Bernouilli** or **multinomial truncated to 1**) where each variable (i.e., word) has two possible values -- `True` if it occurs and `False` if it does not -- we do not consider that here but we could simply replace each frequency with 1 or `True` to implement one of these alternatives.\n",
    "\n",
    "### Exercise 1.1\n",
    "In the cell below, write code that achieves this. Create three lists:\n",
    "- `weather_data_train`: a dictionary containing the data for documents in the class `weather`;\n",
    "- `football_data_train`: a dictionary containing the data for documents in the class `football`;\n",
    "- `train_data`: which is simply `weather_data_train + football_data_train`\n",
    "\n",
    "Hint: this can be done with nested list comprehensions.  This is very similar to the code we used to create document representations for the wordlist classifiers last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1634371866256,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "dpbrvK7dE8vj"
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "weather_data_train=[(FreqDist(sent.split()),\"weather\") for sent in weather_sents_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1634371868680,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "68efmvxvE8vs",
    "outputId": "dbfbd3cb-78e2-4cad-8df0-e533d851fd7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(FreqDist({'is': 1, 'it': 1, 'raining': 1, 'today': 1}), 'weather'),\n",
       " (FreqDist({'cloudy': 1, 'looking': 1, 'today': 1}), 'weather'),\n",
       " (FreqDist({'is': 1, 'it': 1, 'nice': 1, 'weather': 1}), 'weather')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1634371870653,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "AcCCw-2SE8vw"
   },
   "outputs": [],
   "source": [
    "football_data_train=[(FreqDist(sent.split()),\"football\") for sent in football_sents_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1634371870951,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "SSy2yVY2E8vz",
    "outputId": "baf6cfc2-c4a0-4416-a25b-9cf99445e370"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(FreqDist({'is': 1, 'it': 1, 'raining': 1, 'today': 1}), 'weather'),\n",
       " (FreqDist({'cloudy': 1, 'looking': 1, 'today': 1}), 'weather'),\n",
       " (FreqDist({'is': 1, 'it': 1, 'nice': 1, 'weather': 1}), 'weather'),\n",
       " (FreqDist({'city': 1, 'good': 1, 'looking': 1}), 'football'),\n",
       " (FreqDist({'advantage': 1, 'united': 1}), 'football')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=weather_data_train+football_data_train\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdD9ZrkAE8v3"
   },
   "source": [
    "### How a Naïve Bayes classifier works\n",
    "\n",
    "We will now look at how a NB classifier works, using our `weather` versus `football` classification task.\n",
    "\n",
    "In order to classify a document, $d$, we need to determine which of these probabilities is greatest:\n",
    "\n",
    "$$P(\\,\\mbox{weather}\\,|\\,d) \\qquad\\qquad \\mbox{versus} \\qquad\\qquad P(\\,\\mbox{football}\\,|\\,d)$$\n",
    "\n",
    "$d$ could, for example, be the string \"today is looking cloudy\", which would give us:\n",
    "\n",
    "$$P(\\,\\mbox{weather}\\,|\\,\\mbox{\"today is looking cloudy\"}) \\qquad\\qquad \\mbox{versus} \\qquad\\qquad P(\\,\\mbox{football}\\,|\\,\\mbox{\"today is looking cloudy\"})$$\n",
    "\n",
    "The idea is that if the term on the left is higher then the document is in category `weather`, and if the term on the right is higher then the document is in category `football`.\n",
    "\n",
    "$P(X|Y)$ means the probability of $X$ given $Y$. So, $P(\\,\\mbox{weather}\\,|\\,d)$ means the probability, given a document $d$, of $d$ being of class `weather`.\n",
    "\n",
    "We are going to use something called Bayes' rule which states that:\n",
    "\n",
    "$$P(X|Y) = \\frac{P(Y|X)\\cdot P(X)}{P(Y)}$$\n",
    "\n",
    "Applying Bayes' rule to our problem leads to the following comparison:\n",
    "\n",
    "$$\\frac{P(\\,d\\,|\\,\\mbox{weather}\\,)\\cdot P(\\,\\mbox{weather}\\,)}{p(d)} \\qquad\\qquad \\mbox{versus} \\qquad\\qquad \\frac{P(\\,d\\,|\\,\\mbox{football}\\,)\\cdot P(\\,\\mbox{football}\\,)}{p(d)}$$\n",
    "\n",
    "Since both sides are being divided by the same thing, we only need to make the following comparison:\n",
    "\n",
    "$$P(\\,d\\,|\\,\\mbox{weather}\\,)\\cdot P(\\,\\mbox{weather}\\,) \\qquad\\qquad \\mbox{versus} \\qquad\\qquad P(\\,d\\,|\\,\\mbox{football}\\,)\\cdot P(\\,\\mbox{football}\\,)$$\n",
    "\n",
    "Let's just look at what each of these probabilities mean?\n",
    "\n",
    "1. $P(\\,d\\,|\\,\\mbox{weather}\\,)$: this is the probability of a document in the `weather` category being the document $d$\n",
    "\n",
    "2. $P(\\,d\\,|\\,\\mbox{football}\\,)$: this is the probability of a document in the `football` category being the document $d$\n",
    "\n",
    "3. $P(\\,\\mbox{weather}\\,)$: this is the probability of a randomly selected document being of category `weather`.\n",
    "\n",
    "4. $P(\\,\\mbox{football}\\,)$: this is the probability of a randomly selected document being of category `football`.\n",
    "\n",
    "How are we going to obtain these probabilities? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqRuMJE4E8v4"
   },
   "source": [
    "### Class priors\n",
    "\n",
    "We have established that we need to know $P(\\,\\mbox{weather}\\,)$ and $P(\\,\\mbox{football}\\,)$. These are called the class priors. Let's see how we can obtain (estimated) values for these probabilities from our training data.\n",
    "\n",
    "The classifier has seen three documents of class `weather` and two documents of class `football`.\n",
    "\n",
    "From this it learns that `weather` documents are slightly more common that `football` documents, and it therefore has a slight bias towards saying a document is a `weather` document.\n",
    "\n",
    "To be more precise, the classifier has learned that:\n",
    "- The probability that a document is in class `weather` is $3/5$.  \n",
    "We say $P(\\mbox{weather})=3/5=0.6$.\n",
    "\n",
    "- The probability that a document is in class `football` is $2/5$.  \n",
    "We say $P(\\mbox{football})=2/5=0.4$.\n",
    "\n",
    "In general, if the training data contained $n_1$ documents of class `weather` and $n_2$ documents of class `football`, then \n",
    "\n",
    "$$P(\\mbox{weather})=\\frac{n_1}{n_1+n_2} \\qquad \\mbox{and} \\qquad P(\\mbox{football})=\\frac{n_2}{n_1+n_2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxoEwbnGE8v5"
   },
   "source": [
    "### Exercise 1.2\n",
    "In blank the cell below, implement a function `class_priors(training_data)` that takes a dictionary of training data  and returns a dictionary that maps the name of each class to the class prior for that class.\n",
    "\n",
    "Once you have done this, test it out on the training data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1634371929764,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "GcRddZLZE8v5"
   },
   "outputs": [],
   "source": [
    "def class_priors(training_data):\n",
    "    priors={}\n",
    "    for (doc,label) in training_data:\n",
    "        priors[label]=priors.get(label,0)+1\n",
    "    total=sum(priors.values())\n",
    "    for key,value in priors.items():\n",
    "        priors[key]=value/total\n",
    "    return priors\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1634371931142,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "GnbWnBqkE8v8",
    "outputId": "abc9100f-2609-4f94-85a3-1426b8da1a6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'football': 0.4, 'weather': 0.6}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_priors(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NV7TpRLbE8v_"
   },
   "source": [
    "### Conditional probabilities\n",
    "We now turn to the problem of how to calculate (estimates of) the probabilities such as $P(\\,d\\,|\\,\\mbox{weather}\\,)$ and $P(\\,d\\,|\\,\\mbox{football}\\,)$, for some document $d$. The problem we have is that $d$ is a document, potentially a long document, that we won't have seen in the training data.\n",
    "\n",
    "To address this, the Naïve Bayes model of document classification makes a major simplifying assumption.  In particular, it is assumed that the probabiity that different words occur in a document are independent of one another.\n",
    "\n",
    "For example, if $d=\\mbox{\"today is looking cloudy\"}$ then this assumption tells us that:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "P(\\,\\mbox{\"today is looking cloudy\"}\\,|\\,\\mbox{weather}\\,) &=& P(\\{\\mbox{\"today\"},\\mbox{\"is\"},\\mbox{\"looking\"},\\mbox{\"cloudy\"}\\}\\,|\\,\\mbox{weather}\\,)\\\\\n",
    "&=& P(\\,\\mbox{\"today\"}\\,|\\,\\mbox{weather}\\,)\\times P(\\mbox{\"is\"}\\,|\\,\\mbox{weather}\\,)\\times P(\\mbox{\"looking\"}\\,|\\,\\mbox{weather}\\,)\\times P(\\mbox{\"cloudy\"}\\,|\\,\\mbox{weather}\\,)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "For the general case, with class $c$ and document $d=\\{w_1,\\ldots,w_n\\}$, we have:\n",
    "\\begin{eqnarray*}\n",
    "P(\\,d\\,|\\,c\\,) &=& P(\\,\\{w_1,\\ldots,w_n\\}\\,|\\,c\\,)\\\\\n",
    "&=& \\prod_{i=1}^n P(\\,w_i\\,|\\,c\\,)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "The point is that it is plausible that given a reasonable amount of training data, we can make reasonable estimates of the probabilities $P(\\,\\mbox{\"today\"}\\,|\\,\\mbox{weather}\\,)$, $P(\\mbox{\"is\"}\\,|\\,\\mbox{weather}\\,)$, $P(\\mbox{\"looking\"}\\,|\\,\\mbox{weather}\\,)$, and  $P(\\mbox{\"cloudy\"}\\,|\\,\\mbox{weather}\\,)$. \n",
    "\n",
    "We now look at how that is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVX0ciC3E8v_"
   },
   "source": [
    "### Estimating conditional probabilities\n",
    "So we have established that we need estimates of probabilities such as: $P(\\,\\mbox{\"cloudy\"}\\,|\\,\\mbox{weather}\\,)$, $P(\\mbox{\"is\"}\\,|\\,\\mbox{weather}\\,)$, $P(\\mbox{\"today\"}\\,|\\,\\mbox{weather}\\,)$, and $P(\\mbox{\"looking\"}\\,|\\,\\mbox{weather}\\,)$.\n",
    "\n",
    "How can these probabilities be estimated from the training data?\n",
    "\n",
    "Look at the training data we set up above. There are 3 documents of class `weather` and within these documents there are a total of 11 tokens (8 different types).\n",
    "\n",
    "From the data we can estimate the following probabilities:\n",
    "- the probability of seeing \"today\" in a `weather` document is $\\frac{2}{11}$,  \n",
    "i.e. $P(\\mbox{\"today\"}\\,|\\,\\mbox{weather})=\\frac{2}{11}$;\n",
    "- the probability of seeing \"it\" in a `weather` document is $\\frac{2}{11}$,  \n",
    "i.e. $P(\\mbox{\"it\"}\\,|\\,\\mbox{weather})=\\frac{2}{11}$;\n",
    "- the probability of seeing \"is\" in a `weather` document is $\\frac{2}{11}$,  \n",
    "i.e. $P(\\mbox{\"is\"}\\,|\\,\\mbox{weather})=\\frac{2}{11}$;\n",
    "- the probability of seeing \"raining\" in a `weather` document is $\\frac{1}{11}$,  \n",
    "i.e. $P(\\mbox{\"raining\"}\\,|\\,\\mbox{weather})=\\frac{1}{11}$;\n",
    "- the probability of seeing \"looking\" in a `weather` document is $\\frac{1}{11}$,  \n",
    "i.e. $P(\\mbox{\"looking\"}\\,|\\,\\mbox{weather})=\\frac{1}{11}$;\n",
    "- the probability of seeing \"cloudy\" in a `weather` document is $\\frac{1}{11}$,  \n",
    "i.e. $P(\\mbox{\"cloudy\"}\\,|\\,\\mbox{weather})=\\frac{1}{11}$;\n",
    "- the probability of seeing \"nice\" in a `weather` document is $\\frac{1}{11}$,  \n",
    "i.e. $P(\\mbox{\"nice\"}\\,|\\,\\mbox{weather})=\\frac{1}{11}$; and\n",
    "- the probability of seeing \"weather\" in a `weather` document is $\\frac{1}{11}$,  \n",
    "i.e. $P(\\mbox{\"weather\"}\\,|\\,\\mbox{weather})=\\frac{1}{11}$\n",
    "- the probability of seeing any other word in a `weather` document is 0.\n",
    "Notice that all of these conditional probabilities sum to $1$.\n",
    "\n",
    "We can do the same thing for the `football` documents:\n",
    "- the probability of seeing \"city\" in a `football` document is $\\frac{1}{5}$,  \n",
    "i.e. $P(\\mbox{\"city\"}\\,|\\,\\mbox{weather})=\\frac{1}{5}$;\n",
    "- the probability of seeing \"looking\" in a `football` document is $\\frac{1}{5}$,  \n",
    "i.e. $P(\\mbox{\"looking\"}\\,|\\,\\mbox{weather})=\\frac{1}{5}$;\n",
    "- the probability of seeing \"good\" in a `football` document is $\\frac{1}{5}$,  \n",
    "i.e. $P(\\mbox{\"good\"}\\,|\\,\\mbox{weather})=\\frac{1}{5}$;\n",
    "- the probability of seeing \"advantage\" in a `football` document is $\\frac{1}{5}$,  \n",
    "i.e. $P(\\mbox{\"advantage\"}\\,|\\,\\mbox{weather})=\\frac{1}{5}$;\n",
    "- the probability of seeing \"united\" in a `football` document is $\\frac{1}{5}$,  \n",
    "i.e. $P(\\mbox{\"united\"}\\,|\\,\\mbox{weather})=\\frac{1}{5}$;\n",
    "- the probability of seeing any other word in a `football` document is 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4O6vc_RE8wA"
   },
   "source": [
    "### Exercise 1.3\n",
    "We now look at how to implement the calculation of conditional probabilties.\n",
    "\n",
    "In the empty cell below, define a function `cond_probs(training_data)` that takes training data and returns a dictionary that maps the name of a class, $c$, onto a dictionary that maps each word, $w$ to the conditional probability for that word given that class, i.e. $P(w|c)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1634372036672,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "g-36ZInFE8wA"
   },
   "outputs": [],
   "source": [
    "def cond_probs(training_data):\n",
    "    conds={}\n",
    "    for(doc,label) in training_data:\n",
    "\n",
    "        classcond=conds.get(label,{})\n",
    "\n",
    "        for word,value in doc.items():\n",
    "\n",
    "            classcond[word]=classcond.get(word,0)+value\n",
    "        \n",
    "        conds[label]=classcond\n",
    "    print(conds)\n",
    "\n",
    "    \n",
    "    for label,dist in conds.items():\n",
    "        total=sum(dist.values())\n",
    "        conds[label]={key:value/total for (key,value) in dist.items()}\n",
    "        \n",
    "    return conds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1634372038372,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "O0W-G-YAE8wD",
    "outputId": "1e90d8a3-fc54-435c-d91f-6165a9b37537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weather': {'today': 2, 'it': 2, 'is': 2, 'raining': 1, 'looking': 1, 'cloudy': 1, 'nice': 1, 'weather': 1}, 'football': {'city': 1, 'looking': 1, 'good': 1, 'advantage': 1, 'united': 1}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'football': {'advantage': 0.2,\n",
       "  'city': 0.2,\n",
       "  'good': 0.2,\n",
       "  'looking': 0.2,\n",
       "  'united': 0.2},\n",
       " 'weather': {'cloudy': 0.09090909090909091,\n",
       "  'is': 0.18181818181818182,\n",
       "  'it': 0.18181818181818182,\n",
       "  'looking': 0.09090909090909091,\n",
       "  'nice': 0.09090909090909091,\n",
       "  'raining': 0.09090909090909091,\n",
       "  'today': 0.18181818181818182,\n",
       "  'weather': 0.09090909090909091}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_probs(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhd0J-e2E8wF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fccd8F5-E8wI"
   },
   "source": [
    "### Computing the conditional probability of a document\n",
    "\n",
    "We have created implementations of the following functions:\n",
    "- `class_priors(training_data)` that computes estimates of the class priors from training data;\n",
    "- `cond_probs(training_data)` that computes estimates of the conditional probability of a word given a class from training data\n",
    "\n",
    "Let us suppose that we have applied these functions to our training data as follows.\n",
    "\n",
    "```\n",
    "c_priors = class_priors(train_data)\n",
    "c_probs = cond_probs(train_data)\n",
    "```\n",
    "\n",
    "`c_priors` and `c_probs` define the classifier.\n",
    "\n",
    "### Exercise 1.4\n",
    "In the cell below, complete the function `classify(doc,c_priors,c_probs)`. It should return the class that the classifier assigns to the document, `doc`. \n",
    "\n",
    "In the event of a tie, the function should randomly chose one of the classes (see `random.choice`). \n",
    "\n",
    "- Write your function in a way that allows for the possibilty of any number of classes.\n",
    "- Assume that the document, `doc`, is represented as a dictionary that maps words (in the document) to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1634372073209,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "55e05SAeJHHJ",
    "outputId": "fd3b4209-7fb7-4da5-df22-4a15388f5cdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weather': {'today': 2, 'it': 2, 'is': 2, 'raining': 1, 'looking': 1, 'cloudy': 1, 'nice': 1, 'weather': 1}, 'football': {'city': 1, 'looking': 1, 'good': 1, 'advantage': 1, 'united': 1}}\n",
      "dict_values([0.6, 0.4])\n",
      "0.6\n",
      "['weather']\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'weather'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def classify(doc,priors,c_probs):\n",
    "   \n",
    "    doc_probs=priors\n",
    "    #<put your definition of classify here>\n",
    "    #this version just chooses the class with the highest prior probability\n",
    "\n",
    "    highprob=max(doc_probs.values())\n",
    "    print(doc_probs.values())\n",
    "    print(highprob)\n",
    "    classes=[c for c in doc_probs.keys() if doc_probs[c]==highprob]\n",
    "    print(classes)\n",
    "    return random.choice(classes)\n",
    "        \n",
    "c_priors = class_priors(train_data)\n",
    "c_probs = cond_probs(train_data)\n",
    "sent = \"looking cloudy today\"\n",
    "doc = FreqDist(sent.split())\n",
    "classify(doc,c_priors,c_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1634372083706,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "UAVHcfmnE8wJ",
    "outputId": "88b59604-28db-4830-b23b-6d32d0bf7cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weather': {'today': 2, 'it': 2, 'is': 2, 'raining': 1, 'looking': 1, 'cloudy': 1, 'nice': 1, 'weather': 1}, 'football': {'city': 1, 'looking': 1, 'good': 1, 'advantage': 1, 'united': 1}}\n",
      "dict_values([0.0009015777610818934, 0.0])\n",
      "0.0009015777610818934\n",
      "['weather']\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'weather'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def classify(doc,priors,c_probs):\n",
    "\n",
    "    #<put your definition of classify here>\n",
    "    doc_probs=priors\n",
    "    for word in doc.keys():            \n",
    "        doc_probs={classlabel:sofar*c_probs[classlabel].get(word,0) for (classlabel,sofar) in doc_probs.items()}\n",
    "\n",
    "    highprob=max(doc_probs.values())\n",
    "    print(doc_probs.values())\n",
    "    print(highprob)\n",
    "    classes=[c for c in doc_probs.keys() if doc_probs[c]==highprob]\n",
    "    print(classes)\n",
    "    return random.choice(classes)\n",
    "        \n",
    "c_priors = class_priors(train_data)\n",
    "c_probs = cond_probs(train_data)\n",
    "sent = \"looking cloudy today\"\n",
    "doc = FreqDist(sent.split())\n",
    "classify(doc,c_priors,c_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XvxwMGOE8wQ"
   },
   "source": [
    "### A problem\n",
    "There is a problem with the classifier that we have written. \n",
    "\n",
    "### Exercise 2.1\n",
    "* Can you find example sentences which give you different answers on different runs of the classifier\n",
    "* Can you explain why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1634372092589,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "DFq3-1W-E8wR",
    "outputId": "8bffad6f-6fa6-4521-e014-120a580dad47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([0.0, 0.0])\n",
      "0.0\n",
      "['weather', 'football']\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'weather'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"looking cloudy today united city good\"\n",
    "doc = FreqDist(sent.split())\n",
    "classify(doc,c_priors,c_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea0eP8UbE8wT"
   },
   "source": [
    "### Add one smoothing\n",
    "It will often be the case that a word appears in documents of one class, but not in any documents of another class.\n",
    "- For example, consider the document \"city looking cloudy today\".\n",
    "- While \"city\" appears in documents of class `football`, it does not appear in any documents of class `weather`. \n",
    "- Thus, the conditional probabiity $P(\\,\\mbox{city}\\,|\\,\\mbox{weather}\\,)$ is equal to zero.\n",
    "- We are **multiplying** probabilities, so the document ends up with a score of zero even though all of the other words in the document suggest that it is of class `weather`.\n",
    "\n",
    "To get around this we need to do something called **smoothing** in order to avoid zero probabilities. \n",
    "\n",
    "In particular, we will implement a version of smoothing called **add-one smoothing**. This involves adding a count of one to all of the known vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwcQeEiUE8wU"
   },
   "source": [
    "### Known vocabulary\n",
    "The words that appear in documents in the training data are collectively described as the known vocabulary. These are the words that the classifier can learn something about. If the classifier is asked to classify a document that contains any words that are not in the known vocabulary then the classifier will simply ignore them.\n",
    "\n",
    "### Exercise 2.2\n",
    "In the cell below, write a function `known_vocabulary(training_data)` that takes some training and returns a set containing all of words that appear in documents in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1634372096381,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "1VH9M0eLE8wU"
   },
   "outputs": [],
   "source": [
    "def known_vocabulary(training_data):\n",
    "    known=set()\n",
    "    for doc,label in training_data:\n",
    "        for word in list(doc.keys()):\n",
    "          known.add(word)\n",
    "    return known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1634372096600,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "jU93x9myE8wX"
   },
   "outputs": [],
   "source": [
    "vocab=known_vocabulary(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1634372098256,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "6tlopEWwarHC",
    "outputId": "b4735848-6576-4341-94b4-a1477334eba7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1634372098489,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "C56GNJJTayKx",
    "outputId": "ec529128-5192-4b9a-f84c-724ea683818c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'advantage',\n",
       " 'city',\n",
       " 'cloudy',\n",
       " 'good',\n",
       " 'is',\n",
       " 'it',\n",
       " 'looking',\n",
       " 'nice',\n",
       " 'raining',\n",
       " 'today',\n",
       " 'united',\n",
       " 'weather'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yE0atsnbE8wa"
   },
   "source": [
    "### Implementing add-one smoothing\n",
    "As the name suggests, add-one smoothing involves adding counts.\n",
    "\n",
    "In particular, for each word, $w$, in the known vocabulary and each class, $c$, we add one extra count to our record of how many times $w$ appears in documents of class $c$. We are, in effect, hallucinating counts. The reason for doing this is that it means that we avoid zero probabilties.\n",
    "\n",
    "### Exercise 2.3\n",
    "In the blank cell below copy in your code for the `cond_probs` function that you wrote earlier. Then adapt this code so that it implements the add-one smoothing scheme.\n",
    "- You will find it useful to use your `known_vocabulary` function.\n",
    "- If there are $k$ words in your known vocabulary, then you will add $k$ counts for each class. \n",
    "- Therefore, when calculating conditional probabilities, you need to add $k$ to the denominator to account for these extra counts.\n",
    "\n",
    "Test out your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 372,
     "status": "ok",
     "timestamp": 1634372100939,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "Jtx932OYE8wa"
   },
   "outputs": [],
   "source": [
    "def cond_probs(training_data):\n",
    "    conds={}\n",
    "    for(doc,label) in training_data:\n",
    "        classcond=conds.get(label,{})\n",
    "        for word,value in doc.items():\n",
    "            classcond[word]=classcond.get(word,0)+value\n",
    "        \n",
    "        conds[label]=classcond\n",
    "\n",
    "    vocab=known_vocabulary(training_data)\n",
    "    for label, classcond in conds.items():\n",
    "        for word in vocab:\n",
    "        \n",
    "            classcond[word]=classcond.get(word,0)+1\n",
    "        conds[label]=classcond\n",
    "            \n",
    "    for label,dist in conds.items():\n",
    "        total=sum(dist.values())\n",
    "        conds[label]={key:value/total for (key,value) in dist.items()}\n",
    "        \n",
    "    return conds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1634372101265,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "NZNjy3jME8wc",
    "outputId": "759ffd6c-ee96-4d66-8599-dd4f0d2584de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'football': {'advantage': 0.11764705882352941,\n",
       "  'city': 0.11764705882352941,\n",
       "  'cloudy': 0.058823529411764705,\n",
       "  'good': 0.11764705882352941,\n",
       "  'is': 0.058823529411764705,\n",
       "  'it': 0.058823529411764705,\n",
       "  'looking': 0.11764705882352941,\n",
       "  'nice': 0.058823529411764705,\n",
       "  'raining': 0.058823529411764705,\n",
       "  'today': 0.058823529411764705,\n",
       "  'united': 0.11764705882352941,\n",
       "  'weather': 0.058823529411764705},\n",
       " 'weather': {'advantage': 0.043478260869565216,\n",
       "  'city': 0.043478260869565216,\n",
       "  'cloudy': 0.08695652173913043,\n",
       "  'good': 0.043478260869565216,\n",
       "  'is': 0.13043478260869565,\n",
       "  'it': 0.13043478260869565,\n",
       "  'looking': 0.08695652173913043,\n",
       "  'nice': 0.08695652173913043,\n",
       "  'raining': 0.08695652173913043,\n",
       "  'today': 0.13043478260869565,\n",
       "  'united': 0.043478260869565216,\n",
       "  'weather': 0.08695652173913043}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_probs(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PT2--wzJE8wk"
   },
   "source": [
    "### Ignoring OOV words\n",
    "We now look at how to update the `classify` function that we wrote earlier so that it ignores out of vocabulary words that appear in a document being classified.\n",
    "\n",
    "### Exercise 2.4\n",
    "In the blank cell below, copy the `classify` method you wrote earlier and update it so that words not in the known vocabulary are ignored.\n",
    "- You will want to add an additional argument to the `classify` function that is a set containing the known vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1634372102908,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "kItm4EADE8wk",
    "outputId": "66626d88-1f32-446c-ba57-3aff5fedec2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weather': 0.0005917646091887893, 'football': 0.00016283329940972927}\n",
      "['weather']\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'weather'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify(doc,priors,c_probs,known):\n",
    "\n",
    "    doc_probs=priors\n",
    "    for word in doc.keys():\n",
    "        if word in known:\n",
    "            doc_probs={classlabel:sofar*c_probs[classlabel].get(word,0) for (classlabel,sofar) in doc_probs.items()}\n",
    "    print(doc_probs)\n",
    "    highprob=max(doc_probs.values())\n",
    "    classes=[c for c in doc_probs.keys() if doc_probs[c]==highprob]\n",
    "    print(classes)\n",
    "    return random.choice(classes)\n",
    "        \n",
    "c_priors = class_priors(train_data)\n",
    "c_probs = cond_probs(train_data)\n",
    "sent = \"looking cloudy today\"\n",
    "doc = FreqDist(sent.split())\n",
    "classify(doc,c_priors,c_probs,known_vocabulary(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1634372103754,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "PFup4oGJE8wn",
    "outputId": "9567da41-d13b-47c8-f25b-1290c5332df2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weather': 0.006805293005671077, 'football': 0.001384083044982699}\n",
      "['weather']\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'weather'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"looks cloudy today\"\n",
    "doc = FreqDist(sent.split())\n",
    "classify(doc,c_priors,c_probs,known_vocabulary(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxSsPCheE8wq"
   },
   "source": [
    "### Underflow\n",
    "\n",
    "We need to address one final problem concerning the multiplication of probabilities.\n",
    "\n",
    "Recall this equation from earlier:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "P(\\,d\\,|\\,c\\,) &=& P(\\,\\{w_1,\\ldots,w_n\\}\\,|\\,c\\,)\\\\\n",
    "&=& \\prod_{i=1}^n P(\\,w_i\\,|\\,c\\,)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "This tells us that in order to compute $P(\\,d\\,|\\,c\\,)$ for some document $d$ and class $c$, we must multiply $n$ conditional probabilities, one for each word in the document.\n",
    "\n",
    "While in our toy example, this is not an issue. However, in a more realistic settings, where we had thousands of documents, each of which contained multiple paragraphs, we would find ourselves multiplying large numbers of very small probabilities. This would lead to **underflow**.\n",
    "\n",
    "To avoid this problem, we will add the log of probabilties. \n",
    "\n",
    "To understand why this is a reasonable thing to do let us recall a comparison from earlier:\n",
    "\n",
    "$$P(\\,d\\,|\\,\\mbox{weather}\\,)\\cdot P(\\,\\mbox{weather}\\,) \\qquad\\qquad \\mbox{versus} \\qquad\\qquad P(\\,d\\,|\\,\\mbox{football}\\,)\\cdot P(\\,\\mbox{football}\\,)$$\n",
    "\n",
    "Our goal is to determine which of the values (on the left and right) is larger (or determine that they are equal). \n",
    "\n",
    "It should be clear that we will get exactly the same answer to this question by making the following comparsion.\n",
    "\n",
    "$$\\log(P(\\,d\\,|\\,\\mbox{weather}\\,)) + \\log(P(\\,\\mbox{weather}\\,)) \\qquad\\qquad \\mbox{versus} \\qquad\\qquad \\log(P(\\,d\\,|\\,\\mbox{football}\\,)) + \\log(P(\\,\\mbox{football}\\,))$$\n",
    "\n",
    "Thus, rather than calculating conditional probabilities as described above, we will calculate log conditional probabilities like this:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\log(P(\\,\\mbox{\"today is looking cloudy\"}\\,|\\,\\mbox{weather}\\,)) &=& \\log(P(\\{\\mbox{\"today\"},\\mbox{\"is\"},\\mbox{\"looking\"},\\mbox{\"cloudy\"}\\}\\,|\\,\\mbox{weather}\\,))\\\\\n",
    "&=& \\log(P(\\,\\mbox{\"today\"}\\,|\\,\\mbox{weather}\\,))\\ +\\\\\n",
    "&&\\log(P(\\mbox{\"is\"}\\,|\\,\\mbox{weather}\\,))\\ +\\\\\n",
    "&&\\log(P(\\mbox{\"looking\"}\\,|\\,\\mbox{weather}\\,))\\ + \\\\\n",
    "&&\\log(P(\\mbox{\"cloudy\"}\\,|\\,\\mbox{weather}\\,))\n",
    "\\end{eqnarray*}\n",
    "\n",
    "For the general case, with class $c$ and document $d=\\{w_1,\\ldots,w_n\\}$, we have:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\log(P(\\,d\\,|\\,c\\,)) &=& \\log(P(\\,\\{w_1,\\ldots,w_n\\}\\,|\\,c\\,))\\\\\n",
    "&=& \\sum_{i=1}^n \\log(P(\\,w_i\\,|\\,c\\,))\n",
    "\\end{eqnarray*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fZ0sJdsE8wr"
   },
   "source": [
    "### Exercise 2.6\n",
    "In the blank cell below, make a copy of the cell containing the definition of `classify`.\n",
    "\n",
    "Adapt the code so that it adds logs of probabilties rather than multiplies probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1634372105916,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "GAPskFACE8ww",
    "outputId": "6d918f74-0cd1-4665-9718-c74f5710c0a2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'weather'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def classify(doc,priors,c_probs,known):\n",
    "\n",
    "    doc_probs={key:math.log(value) for (key,value) in priors.items()}\n",
    "    #<put your definition of classify here>\n",
    "   \n",
    "    highprob=max(doc_probs.values())\n",
    "    classes=[c for c in doc_probs.keys() if doc_probs[c]==highprob]\n",
    "    return random.choice(classes)\n",
    "        \n",
    "c_priors = class_priors(train_data)\n",
    "c_probs = cond_probs(train_data)\n",
    "sent = \"looking cloudy today\"\n",
    "doc = FreqDist(sent.split())\n",
    "classify(doc,c_priors,c_probs,known_vocabulary(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1634372107148,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "mCIChoNzE8wt",
    "outputId": "b4cf6d97-ca74-41bf-a70c-7690a0478413"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'weather'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def classify(doc,priors,c_probs,known):\n",
    "\n",
    "    doc_probs={key:math.log(value) for (key,value) in priors.items()}\n",
    "    #<put your definition of classify here>\n",
    "    for word in doc.keys():\n",
    "        if word in known:\n",
    "            doc_probs={classlabel:sofar+math.log(c_probs[classlabel].get(word,0)) for (classlabel,sofar) in doc_probs.items()}\n",
    "\n",
    "    highprob=max(doc_probs.values())\n",
    "    classes=[c for c in doc_probs.keys() if doc_probs[c]==highprob]\n",
    "    return random.choice(classes)\n",
    "        \n",
    "c_priors = class_priors(train_data)\n",
    "c_probs = cond_probs(train_data)\n",
    "sent = \"looking cloudy today\"\n",
    "doc = FreqDist(sent.split())\n",
    "classify(doc,c_priors,c_probs,known_vocabulary(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lUI4BQlE8wz"
   },
   "source": [
    "### Constructing a Naïve Bayes classifier\n",
    "\n",
    "We are now almost ready to run our Naïve Bayes classifier on a set of test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1634372108901,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "-2jJaQ41E8wz"
   },
   "outputs": [],
   "source": [
    "weather_sents_test = [\n",
    "    \"the weather today is nice\",\n",
    "    \"it is raining cats and dogs\",\n",
    "    \"the weather here is wet\",\n",
    "    \"it was hot today\",\n",
    "    \"rain due tomorrow\",\n",
    "]\n",
    "\n",
    "football_sents_test = [\n",
    "    \"what a great goal that was\",\n",
    "    \"poor defending by the city center back\",\n",
    "    \"wow he missed a sitter\",\n",
    "    \"united are a shambles\",\n",
    "    \"shots raining down on the keeper\",\n",
    "]\n",
    "\n",
    "weather_data_test = [(FreqDist(sent.split()), \"weather\") for sent in weather_sents_test] \n",
    "football_data_test = [(FreqDist(sent.split()), \"football\") for sent in football_sents_test]\n",
    "test_data = weather_data_test + football_data_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1634372110406,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "hivIdxVcdxHl",
    "outputId": "d4d3507f-5b5c-4561-ea9c-10fa14d1d59c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(FreqDist({'is': 1, 'nice': 1, 'the': 1, 'today': 1, 'weather': 1}),\n",
       "  'weather'),\n",
       " (FreqDist({'and': 1, 'cats': 1, 'dogs': 1, 'is': 1, 'it': 1, 'raining': 1}),\n",
       "  'weather'),\n",
       " (FreqDist({'here': 1, 'is': 1, 'the': 1, 'weather': 1, 'wet': 1}), 'weather'),\n",
       " (FreqDist({'hot': 1, 'it': 1, 'today': 1, 'was': 1}), 'weather'),\n",
       " (FreqDist({'due': 1, 'rain': 1, 'tomorrow': 1}), 'weather'),\n",
       " (FreqDist({'a': 1, 'goal': 1, 'great': 1, 'that': 1, 'was': 1, 'what': 1}),\n",
       "  'football'),\n",
       " (FreqDist({'back': 1,\n",
       "            'by': 1,\n",
       "            'center': 1,\n",
       "            'city': 1,\n",
       "            'defending': 1,\n",
       "            'poor': 1,\n",
       "            'the': 1}),\n",
       "  'football'),\n",
       " (FreqDist({'a': 1, 'he': 1, 'missed': 1, 'sitter': 1, 'wow': 1}), 'football'),\n",
       " (FreqDist({'a': 1, 'are': 1, 'shambles': 1, 'united': 1}), 'football'),\n",
       " (FreqDist({'down': 1,\n",
       "            'keeper': 1,\n",
       "            'on': 1,\n",
       "            'raining': 1,\n",
       "            'shots': 1,\n",
       "            'the': 1}),\n",
       "  'football')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7Cbil0NE8w1"
   },
   "source": [
    "### Exercise 2.7\n",
    "* Complete the NBClassifier `class` which can be used to carry out classification.  Add your code (from earlier) to the methods `set_known_vocabulary`, `set_priors` and `set_cond_probs` and `classify`.  \n",
    "* Run your NB classifier on both the training data and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "error",
     "timestamp": 1634372116856,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "zMFlAD9vJHHP",
    "outputId": "b9d5f4b7-aef4-44b1-d2d7-7ac85516f82c"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-2a546e84219b>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    def _set_priors(self,training_data):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.api import ClassifierI\n",
    "\n",
    "class NBClassifier(ClassifierI):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def _set_known_vocabulary(self,training_data):\n",
    "        #add your code here\n",
    "        \n",
    "    \n",
    "    def _set_priors(self,training_data):\n",
    "        #add your code here \n",
    "        \n",
    "        \n",
    "    def _set_cond_probs(self,training_data):       \n",
    "        #add your code here\n",
    "        \n",
    "    \n",
    "    def train(self,training_data):\n",
    "        self._set_known_vocabulary(training_data)\n",
    "        self._set_priors(training_data)\n",
    "        self._set_cond_probs(training_data)\n",
    "    \n",
    "    def classify(self,doc):\n",
    "        #add your code here\n",
    "        \n",
    "    \n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1634372120741,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "w3rndQKBE8w2"
   },
   "outputs": [],
   "source": [
    "from nltk.classify.api import ClassifierI\n",
    "\n",
    "class NBClassifier(ClassifierI):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def _set_known_vocabulary(self,training_data):\n",
    "        #add your code here\n",
    "        known=[]\n",
    "        for doc,label in training_data:\n",
    "            known+=list(doc.keys())\n",
    "        self.known= set(known)\n",
    "    \n",
    "    def _set_priors(self,training_data):\n",
    "        #add your code here \n",
    "        priors={}\n",
    "        for (doc,label) in training_data:\n",
    "            priors[label]=priors.get(label,0)+1\n",
    "        total=sum(priors.values())\n",
    "        for key,value in priors.items():\n",
    "            priors[key]=value/total\n",
    "        self.priors=priors\n",
    "        \n",
    "    def _set_cond_probs(self,training_data):       \n",
    "        #add your code here\n",
    "        conds={}\n",
    "        for(doc,label) in training_data:\n",
    "            classcond=conds.get(label,{})\n",
    "            for word in doc.keys():\n",
    "                classcond[word]=classcond.get(word,0)+1\n",
    "        \n",
    "            conds[label]=classcond\n",
    "    \n",
    "        for label, classcond in conds.items():\n",
    "            for word in self.known:\n",
    "        \n",
    "                classcond[word]=classcond.get(word,0)+1\n",
    "            conds[label]=classcond\n",
    "            \n",
    "        for label,dist in conds.items():\n",
    "            total=sum(dist.values())\n",
    "            conds[label]={key:value/total for (key,value) in dist.items()}\n",
    "        \n",
    "        self.conds=conds\n",
    "    \n",
    "    def train(self,training_data):\n",
    "        self._set_known_vocabulary(training_data)\n",
    "        self._set_priors(training_data)\n",
    "        self._set_cond_probs(training_data)\n",
    "    \n",
    "    def classify(self,doc):\n",
    "        #add your code here\n",
    "        doc_probs={key:math.log(value) for (key,value) in self.priors.items()}\n",
    "        for word in doc.keys():\n",
    "            if word in self.known:\n",
    "                doc_probs={classlabel:sofar+math.log(self.conds[classlabel].get(word,0)) for (classlabel,sofar) in doc_probs.items()}\n",
    "\n",
    "        highprob=max(doc_probs.values())\n",
    "        classes=[c for c in doc_probs.keys() if doc_probs[c]==highprob]\n",
    "        return random.choice(classes)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1634372123407,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "dRfA3ZZfE8w6",
    "outputId": "a2577492-a973-4550-ec64-4c30599deae7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather',\n",
       " 'weather',\n",
       " 'weather',\n",
       " 'weather',\n",
       " 'weather',\n",
       " 'weather',\n",
       " 'football',\n",
       " 'weather',\n",
       " 'football',\n",
       " 'weather']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create an instance of an NBClassifier and apply it to the test data\n",
    "myclassifier=NBClassifier()\n",
    "myclassifier.train(train_data)\n",
    "myclassifier.classify_many(doc for (doc,label) in test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_9n-advE8w8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_4_1_SOLUTIONS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
