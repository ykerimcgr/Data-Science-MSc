{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjIgwH4mURxe"
   },
   "source": [
    "# Lab 3: Document Classification (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCv5KJOCURxf"
   },
   "source": [
    "### Overview\n",
    "This topic builds on the activities of the previous topic on sentiment analysis. You will be focussing on the movie review corpus with a view to investigating the following issues.\n",
    "\n",
    "- Evaluation metrics for classifier performance\n",
    "- What is the impact of varying training data size? To what extent does increasing the quantity of training data improve classifier performance?\n",
    "\n",
    "By this stage, you should be very comfortable with Python's [list comprehensions](http://docs.python.org/tutorial/datastructures.html#list-comprehensions) and [slice](http://bergbom.blogspot.co.uk/2011/04/python-slice-notation.html) notation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LirziHXVURxh"
   },
   "source": [
    ">To access functionality defined in previous notebooks, copy the functions defined in Week3Labs into a `utils.py` file and then import it into the notebook.  There is a `utils.py` file included with these resources which you can update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1633609436229,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "6Im4wuOJr66N",
    "outputId": "7ea421bb-faf7-497b-ce62-5dce68ee0d06"
   },
   "outputs": [],
   "source": [
    "##uncomment the following lines on colab\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1633609510817,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "Jtr8YFODsUUh",
    "outputId": "cfe414a9-eed5-48c4-bf9c-74f0c3e285d0"
   },
   "outputs": [],
   "source": [
    "#other needed imports\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "import pandas as pd\n",
    "#this next line will ensure pandas graphs are plotted in the notebook\n",
    "%matplotlib inline  \n",
    "\n",
    "##download stopwords and movie_reviews - need to do this every session on colab\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1633609446817,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "Zb62QpRpURxi"
   },
   "outputs": [],
   "source": [
    "#set your system path so that jupyter knows where to look for other files\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/NLE Notebooks 2021/Week3LabsSolutions/')\n",
    "#import code to setup training and testing data, wordlist classifiers and NB classifiers\n",
    "from utils import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mZap-2rURxr"
   },
   "source": [
    "## Evaluation Metrics for Classifier Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juCwCS-dURxr"
   },
   "source": [
    "### Accuracy\n",
    "Here is code for an evaluation function <code>evaluate_wordlist_classifier</code> which can be used to determine how well a word_list classifier performs. This function returns the <b>accuracy</b> of a classifier. The accuracy metric is defined as the proportion of documents that were correctly classified.  Look at the code and make sure you understand what it is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1633609451305,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "Kf4kWgpZCLYi"
   },
   "outputs": [],
   "source": [
    "def classifier_evaluate(cls, test_data):\n",
    "    '''\n",
    "    cls: an instance of a classifier object which has a classify method which returns \"pos\" or \"neg\"\n",
    "    test_data: a list of pairs where each pair is a FreqDist rep of a doc and its label\n",
    "  \n",
    "    returns: float point number which is the accuracy of the classifier on the test data provided \n",
    "    '''\n",
    "    acc = 0\n",
    "    docs,goldstandard=zip(*test_data) #note this neat pythonic way of turning a list of pairs into a pair of lists\n",
    "    #pass all of the docs to the classifier and get back a list of predictions\n",
    "    predictions=cls.classify_many(docs)\n",
    "    #zip the predictions with the goldstandard labels and compare\n",
    "    for prediction,goldlabel in zip(predictions,goldstandard):\n",
    "        if prediction==goldlabel:\n",
    "            acc+=1\n",
    "    \n",
    "    return acc / (len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ki1vS7WGVYQ4"
   },
   "source": [
    "Now we need some data to train and test our classifier on.  We are going to make use of the code from the lab_3_1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1633609458856,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "aKjfbLU0VYd9"
   },
   "outputs": [],
   "source": [
    "def get_train_test_data():\n",
    "    \n",
    "    #get ids of positive and negative movie reviews\n",
    "    pos_review_ids=movie_reviews.fileids('pos')\n",
    "    neg_review_ids=movie_reviews.fileids('neg')\n",
    "   \n",
    "    #split positive and negative data into training and testing sets\n",
    "    pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
    "    neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n",
    "    #add labels to the data and concatenate\n",
    "    training = [(movie_reviews.words(f),'pos') for f in pos_train_ids]+[(movie_reviews.words(f),'neg') for f in neg_train_ids]\n",
    "    testing = [(movie_reviews.words(f),'pos') for f in pos_test_ids]+[(movie_reviews.words(f),'neg') for f in neg_test_ids]\n",
    "    #now normalise and create bag-of-words FreqDist representations\n",
    "    training_norm=[(FreqDist(normalise(wordlist)),label) for (wordlist,label) in training]\n",
    "    testing_norm=[(FreqDist(normalise(wordlist)),label) for (wordlist,label) in testing]\n",
    "    return training_norm, testing_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5347,
     "status": "ok",
     "timestamp": 1633609524590,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "2NsOsDS2aJXY",
    "outputId": "87298b5a-1342-45a6-dcca-8120b7c6330d"
   },
   "outputs": [],
   "source": [
    "random.seed(41)  #set the random seeds so these random splits are always the same\n",
    "training,testing=get_train_test_data()\n",
    "\n",
    "training[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_T9kB9w0Dv_k"
   },
   "source": [
    "We are now going to use this function to start evaluating our classifiers from last week.  Lets first try the SimpleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 177,
     "status": "ok",
     "timestamp": 1633609530622,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "M9b7hwEuURxs",
    "outputId": "83f0c2ca-c8d2-4d13-f5e8-532b1fdde68e"
   },
   "outputs": [],
   "source": [
    "#here I am going to create an instance of a very simple classifier \n",
    "\n",
    "my_positive_word_list = [\"good\",\"great\",\"lovely\", \"excellent\"] # extend this one or put your own list here\n",
    "my_negative_word_list = [\"bad\", \"terrible\", \"awful\", \"dreadful\"] # extend this one or put your own list here\n",
    "movie_classifier1 = SimpleClassifier(my_positive_word_list,my_negative_word_list)\n",
    "\n",
    "#Evaluate classifier\n",
    "#The function requires two arguments:\n",
    "# 1. Word list based classifer\n",
    "# 2. A list (or generator) of labelled test items\n",
    "score = classifier_evaluate(movie_classifier1, testing)  \n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRCS5zwlURxv"
   },
   "source": [
    "If you have run the cell above without updating the SimpleClassifier code you should see that the accuracy is 0.5 i.e., 50%. The original SimpleClassifier just assigns everything to the positive class.  Since it is a binary classification decision and the classes are balanced, it will get 50% of the decisions correct (those that are positive) and 50% of the decisions incorrect (those that are actually negative).  This is the **baseline** result for this kind of classification task.  We obviously want to build classifiers that do better than this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxDIMt53EUby"
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "Now you try one of the classifiers that you wrote that selects positive and negative words from the training data.  Hopefully, this will perform better than the baseline of 50%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3268,
     "status": "ok",
     "timestamp": 1633609536876,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "xlNs8VBdET2e",
    "outputId": "cfb53737-530c-4ce1-fffa-f36f695087bc"
   },
   "outputs": [],
   "source": [
    "#Create a new classifier\n",
    "#Make sure you have updated the code in utils.py to contain your WordList Classifier\n",
    "#If you update the utils.py code mid-session, you will need to restart the runtime / kernel in order to force it to import the new updated code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1633609539315,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "QKxbaLFtURxw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nm7UGczgURyd"
   },
   "source": [
    "## Precision, Recall and F1 score etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c74BIeN6URye"
   },
   "source": [
    "When classes are unbalanced, evaluating classifiers in terms of accuracy can be misleading.  For example, if 10% of documents are relevant and 90% of documents are irrelevant, then a classifier which labels all documents as irrelevant will obtain an accuracy of 90%.  This sounds good but is actually useless. More useful metrics for evaluation of performance are precision, recall and F1 score.  These metrics allow us to distinguish the different types of errors our classifiers make.\n",
    "\n",
    "For each class, $c$, we need to keep a record of \n",
    "* True Positives: $TP=|\\{i|\\mbox{prediction}(i)=\\mbox{label}(i)=c\\}|$\n",
    "* False Negatives: $FN=|\\{i|\\mbox{prediction}(i)\\neq \\mbox{label}(i)=c\\}|$\n",
    "* False Positives: $FP=|\\{i|\\mbox{label}(i) \\neq \\mbox{prediction}(i)=c\\}|$\n",
    "* True Negatives: $TN=|\\{i|\\mbox{prediction}(i)=\\mbox{label}(i)\\neq c\\}|$\n",
    "\n",
    "Note the symmetry in the binary classification task (the TN for one class are the TP for the other class and so on).  Therefore, in binary classification, we just record these values and compute the following evaluation metrics for a single class (e.g. \"Relevant\" or \"Positive\")\n",
    "\n",
    "* Precision: \n",
    "\\begin{eqnarray*}\n",
    "P=\\frac{TP}{TP+FP}\n",
    "\\end{eqnarray*}\n",
    "* Recall: \n",
    "\\begin{eqnarray*}\n",
    "R=\\frac{TP}{TP+FN}\n",
    "\\end{eqnarray*}\n",
    "* F1-score: \n",
    "\\begin{eqnarray*}\n",
    "F1 = \\frac{2\\times P\\times R}{P+R}\n",
    "\\end{eqnarray*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvEQsGi0URye"
   },
   "source": [
    " ### Exercise 2.1\n",
    " \n",
    " The code below defines a ConfusionMatrix class for the binary classification task.  Currently, it will compute the number of TPs, FPs, FNs and TNs.  Test it out with predictions and test data for our sentiment analysis task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1633609540175,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "fvhIJN-9URyf"
   },
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "    def __init__(self,predictions,goldstandard,classes=(\"pos\",\"neg\")):\n",
    "    \n",
    "        (self.c1,self.c2)=classes\n",
    "        self.TP=0\n",
    "        self.FP=0\n",
    "        self.FN=0\n",
    "        self.TN=0\n",
    "        for p,g in zip(predictions,goldstandard):\n",
    "            if g==self.c1:\n",
    "                if p==self.c1:\n",
    "                    self.TP+=1\n",
    "                else:\n",
    "                    self.FN+=1\n",
    "        \n",
    "            elif p==self.c1:\n",
    "                self.FP+=1\n",
    "            else:\n",
    "                self.TN+=1\n",
    "        \n",
    "    \n",
    "    def precision(self):\n",
    "        p=0\n",
    "        #put your code to compute precision here\n",
    "    \n",
    "        return p\n",
    "  \n",
    "    def recall(self):\n",
    "        r=0\n",
    "        #put your code to compute recall here\n",
    "    \n",
    "        return r\n",
    "  \n",
    "    def f1(self):\n",
    "        f1=0\n",
    "        #put your code to compute f1 here\n",
    "      \n",
    "        return f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1633609541702,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "SUOy77CNURyk",
    "outputId": "0d253df8-185b-4b29-966f-181d88a1876c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNsc3JO5URyx"
   },
   "source": [
    "### Exercise 2.2\n",
    "* Add functionality to the ConfusionMatrix class code to compute precision, recall and F1 score\n",
    "* Use your code to evaluate the performance of the different classifiers you have constructed.\n",
    "* Interpret your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1633609543762,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "TKKAh-8iURyx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j38Nt0rPURy1"
   },
   "source": [
    "## Investigating the impact of the quantity of training data\n",
    "We will begin by exploring the impact on classification accuracy of using different quantities of training data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Nw5k_3WURy3"
   },
   "source": [
    "Run the code in the cell below several times.  Each time it should generate a new sample of review data, train the classifiers and evaluate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "executionInfo": {
     "elapsed": 10830,
     "status": "ok",
     "timestamp": 1633609555907,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "oTu-mhEkURy3",
    "outputId": "58584d6d-5187-4d8d-eb2d-d895c3e6b935"
   },
   "outputs": [],
   "source": [
    "\n",
    "training,testing=get_train_test_data()\n",
    "\n",
    "word_list_size = 100\n",
    "threshold=100\n",
    "classifiers={\"Word List MF\":SimpleClassifier_mf(word_list_size),\n",
    "             \"Word List Thresh\":SimpleClassifier_ot(threshold)}\n",
    "\n",
    "results=[]\n",
    "for name,classifier in classifiers.items():\n",
    "    classifier.train(training)\n",
    "    accuracy=classifier_evaluate(classifier,testing)\n",
    "    print(\"The accuracy of {} classifier is {}\".format(name,accuracy))\n",
    "    results.append((name,accuracy))\n",
    "             \n",
    "df = pd.DataFrame(results)\n",
    "display(df)\n",
    "ax = df.plot.bar(title=\"Experimental Results\",legend=False,x=0)\n",
    "ax.set_ylabel(\"Classifier Accuracy\")\n",
    "ax.set_xlabel(\"Classifier\")\n",
    "ax.set_ylim(0,1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C08xFmkcURy6"
   },
   "source": [
    "As you can see, the classifiers have different accuracies on different runs. \n",
    "\n",
    "### Exercise 3.1\n",
    "Copy the cell above and move the copy to be positioned below this cell. Then adapt the code so that the accuracy reported for each classifier is the average across multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "executionInfo": {
     "elapsed": 33478,
     "status": "ok",
     "timestamp": 1633609596696,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "yMxDKCTYrzxT",
    "outputId": "1b1a45c6-f098-4708-b890-e6267ed6225d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ci_vzc-cURzJ"
   },
   "source": [
    "### Exercise 3.2\n",
    "Adapt the code so that it calculates average precision, recall and F1-score rather than average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "executionInfo": {
     "elapsed": 32296,
     "status": "ok",
     "timestamp": 1633609724451,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "eu99TOHErzxU",
    "outputId": "f99470d7-7753-4333-8e32-6abbc4f5fb5a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GP50O9lgURzM"
   },
   "source": [
    "### Exercise 3.3\n",
    "Investigate the impact of training data size on the performance of both word list classifiers, using a range of subsets of movie reviews.\n",
    "\n",
    "Hints and tips.\n",
    "- You can copy the code cell that you created for the last exercise, and place the copy below this cell. Then adapt the code to determine accuracy, precision, recall and F1-score for each classifier on each subset.\n",
    "\n",
    "- Use the `sample` function from the random module. \n",
    "- Remember, the full data set has 1000 positive and 1000 negative reviews. \n",
    "- You should continue to use 30% of the data for testing, so this means that we have up to 700 positive and 700 negative reviews to sample from.\n",
    "- Make sure that you are selecting samples that have an equal number of positive and negative reviews.\n",
    "- Consider (at least) the following sample sizes: 2, 10, 50, 100, 200, 400, 600 and 700.\n",
    "- Note that the sample size is not the total number of reviews, but the number of positive reviews (which is also equal to the number of negative reviews).\n",
    "\n",
    "\n",
    "**Interpret your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 182643,
     "status": "ok",
     "timestamp": 1633609907070,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "PDNqN7QFURzN",
    "outputId": "69fcf3e2-dbad-4b85-c7b0-dfede2a2b8a1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 186,
     "status": "ok",
     "timestamp": 1633610045103,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "cfg4Y9UgrzxV",
    "outputId": "425ecb48-6aa5-4fee-bbec-115c68320227"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1633610047536,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "dr7t6a5El82f",
    "outputId": "41c041d4-d2b4-475c-ffca-5e12fb4d9e3b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GA-qFH0vuGse"
   },
   "source": [
    "My answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRi4wCz3mElF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_d9oBaz2URzR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_3_2_SOLUTONS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
